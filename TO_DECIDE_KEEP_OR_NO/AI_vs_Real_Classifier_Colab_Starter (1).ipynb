{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dff5f7f3",
      "metadata": {
        "id": "dff5f7f3"
      },
      "source": [
        "\n",
        "# üîç AI-Generated vs. Real Image Classifier (Colab Starter)\n",
        "\n",
        "This notebook trains a simple baseline classifier to distinguish **AI-generated** images from **real** images using transfer learning (EfficientNetB0) in Keras. It includes:\n",
        "- GPU setup check\n",
        "- Two data ingestion options (Google Drive folder or Kaggle download)\n",
        "- Data augmentation\n",
        "- Transfer learning (frozen base ‚Üí fine-tune)\n",
        "- Metrics & confusion matrix\n",
        "- **Grad-CAM** visualizations for \"why the model thinks so\"\n",
        "\n",
        "> **Folder structure expected (if using Drive):**\n",
        ">\n",
        "> ```\n",
        "> /MyDrive/datasets/aivsreal/\n",
        ">   train/\n",
        ">     ai/\n",
        ">     real/\n",
        ">   val/\n",
        ">     ai/\n",
        ">     real/\n",
        ">   test/\n",
        ">     ai/\n",
        ">     real/\n",
        "> ```\n",
        ">\n",
        "> Upload dataset here.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkU76Yx7om2B",
        "outputId": "62acc9c6-1257-4ecc-d62c-da134c4e8cf9"
      },
      "id": "VkU76Yx7om2B",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a12941ad",
      "metadata": {
        "id": "a12941ad"
      },
      "source": [
        "## 0) Runtime setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "504bab35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "504bab35",
        "outputId": "0c9a7a74-82c5-4be2-fbd7-9f2a4d0a4a3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow: 2.19.0\n",
            "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# If using Colab, set: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c86fa90a",
      "metadata": {
        "id": "c86fa90a"
      },
      "source": [
        "## 1) Mount Google Drive (recommended)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "59a55cbd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59a55cbd",
        "outputId": "0a8ba434-de69-4339-c066-7d63b9cf7b36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using DATA_DIR: /content/drive/MyDrive/Datasets/aivsreal\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# üëá Change this path to where your dataset lives in Drive\n",
        "DATA_DIR = \"/content/drive/MyDrive/Datasets/aivsreal\"\n",
        "print(\"Using DATA_DIR:\", DATA_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f22f47f7",
      "metadata": {
        "id": "f22f47f7"
      },
      "source": [
        "\n",
        "## (Optional) 1b) Download a dataset via Kaggle\n",
        "\n",
        "If you have a Kaggle dataset you'd like to use, do this once per session:\n",
        "1. Create an API token at https://www.kaggle.com/settings/account (click \"Create New API Token\").\n",
        "2. Upload the downloaded `kaggle.json` using the cell below.\n",
        "3. Replace the example dataset path with your chosen dataset slug.\n",
        "\n",
        "> Tip: Many datasets already have `train/val/test` or `train/test`. If not, you can split after download.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ba2b661b",
      "metadata": {
        "id": "ba2b661b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Uncomment to use Kaggle (run step-by-step):\n",
        "# from google.colab import files\n",
        "# files.upload()  # upload kaggle.json\n",
        "# !mkdir -p ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# EXAMPLE: Replace with your dataset (this is a placeholder; change to a real one you select)\n",
        "# !kaggle datasets download -d <owner>/<dataset-slug> -p /content/data\n",
        "# !unzip -q /content/data/*.zip -d /content/data\n",
        "\n",
        "# After unzip, set DATA_DIR to the folder that contains class subfolders (ai/ real/)\n",
        "# DATA_DIR = \"/content/data/<folder_with_class_subdirs>\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83feaa5e",
      "metadata": {
        "id": "83feaa5e"
      },
      "source": [
        "## 2) Build datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1a4158e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "1a4158e6",
        "outputId": "208d58ce-4b7b-420a-ee89-c1e6f0c5f0fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 files belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No images found in directory /content/drive/MyDrive/Datasets/aivsreal/train. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1099097362.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtry_load_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mval_ds\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtry_load_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mtest_ds\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtry_load_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1099097362.py\u001b[0m in \u001b[0;36mtry_load_dataset\u001b[0;34m(split_name)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msplit_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         ds = keras.preprocessing.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0msplit_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/image_dataset_utils.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[0m\n\u001b[1;32m    327\u001b[0m         )\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    330\u001b[0m                 \u001b[0;34mf\"No images found in directory {directory}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0;34mf\"Allowed formats: {ALLOWLIST_FORMATS}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No images found in directory /content/drive/MyDrive/Datasets/aivsreal/train. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "SEED = 1337\n",
        "\n",
        "# Helper to load a split if it exists; else return None\n",
        "def try_load_dataset(split_name):\n",
        "    split_dir = os.path.join(DATA_DIR, split_name)\n",
        "    if os.path.isdir(split_dir):\n",
        "        ds = keras.preprocessing.image_dataset_from_directory(\n",
        "            split_dir,\n",
        "            image_size=IMG_SIZE,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            seed=SEED,\n",
        "            label_mode='categorical'  # 2 classes: [ai, real]\n",
        "        )\n",
        "        return ds\n",
        "    return None\n",
        "\n",
        "train_ds = try_load_dataset(\"train\")\n",
        "val_ds   = try_load_dataset(\"val\")\n",
        "test_ds  = try_load_dataset(\"test\")\n",
        "\n",
        "# If no /val, split from train\n",
        "if train_ds is not None and val_ds is None:\n",
        "    val_size = 0.2\n",
        "    train_ds = keras.preprocessing.image_dataset_from_directory(\n",
        "        os.path.join(DATA_DIR, \"train\"),\n",
        "        image_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        validation_split=val_size,\n",
        "        subset=\"training\",\n",
        "        seed=SEED,\n",
        "        label_mode='categorical'\n",
        "    )\n",
        "    val_ds = keras.preprocessing.image_dataset_from_directory(\n",
        "        os.path.join(DATA_DIR, \"train\"),\n",
        "        image_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        validation_split=val_size,\n",
        "        subset=\"validation\",\n",
        "        seed=SEED,\n",
        "        label_mode='categorical'\n",
        "    )\n",
        "\n",
        "if train_ds is None:\n",
        "    raise SystemExit(\"‚ùå Could not find a 'train/' folder inside DATA_DIR. See the expected structure above.\")\n",
        "\n",
        "# Cache+prefetch\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "def configure(ds):\n",
        "    return ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "train_ds = configure(train_ds)\n",
        "val_ds   = configure(val_ds) if val_ds is not None else None\n",
        "test_ds  = configure(test_ds) if test_ds is not None else None\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(\"Classes:\", class_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63e11fca",
      "metadata": {
        "id": "63e11fca"
      },
      "source": [
        "## 3) Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4be588a",
      "metadata": {
        "id": "e4be588a"
      },
      "outputs": [],
      "source": [
        "\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.05),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.RandomContrast(0.1),\n",
        "], name=\"augmentation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09ef4f81",
      "metadata": {
        "id": "09ef4f81"
      },
      "source": [
        "## 4) Build the model (EfficientNetB0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "025e0f81",
      "metadata": {
        "id": "025e0f81"
      },
      "outputs": [],
      "source": [
        "\n",
        "base = keras.applications.EfficientNetB0(\n",
        "    include_top=False, input_shape=IMG_SIZE + (3,), weights=\"imagenet\"\n",
        ")\n",
        "base.trainable = False  # freeze for initial training\n",
        "\n",
        "inputs = keras.Input(shape=IMG_SIZE + (3,))\n",
        "x = data_augmentation(inputs)\n",
        "x = keras.applications.efficientnet.preprocess_input(x)\n",
        "x = base(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.25)(x)\n",
        "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b480cb02",
      "metadata": {
        "id": "b480cb02"
      },
      "source": [
        "## 5) Train (Stage 1: frozen base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72995ba6",
      "metadata": {
        "id": "72995ba6"
      },
      "outputs": [],
      "source": [
        "\n",
        "EPOCHS_1 = 5  # You can increase later\n",
        "history1 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS_1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4abd0bb7",
      "metadata": {
        "id": "4abd0bb7"
      },
      "source": [
        "## 6) Fine-tune (unfreeze top of base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12b732db",
      "metadata": {
        "id": "12b732db"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Unfreeze top blocks for gentle fine-tuning\n",
        "base.trainable = True\n",
        "for layer in base.layers[:-40]:  # unfreeze last ~40 layers\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "EPOCHS_2 = 5  # You can increase later\n",
        "history2 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS_2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "718939ee",
      "metadata": {
        "id": "718939ee"
      },
      "source": [
        "## 7) Evaluate and Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ac70643",
      "metadata": {
        "id": "8ac70643"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "# Pick test_ds if available, else use val_ds for quick eval\n",
        "eval_ds = test_ds if test_ds is not None else val_ds\n",
        "\n",
        "if eval_ds is None:\n",
        "    raise SystemExit(\"‚ùå No validation or test set found. Please create a 'val/' or 'test/' split.\")\n",
        "\n",
        "y_true = np.concatenate([y.numpy() for _, y in eval_ds], axis=0)\n",
        "y_true_lbl = np.argmax(y_true, axis=1)\n",
        "\n",
        "y_pred_prob = model.predict(eval_ds)\n",
        "y_pred_lbl = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "print(classification_report(y_true_lbl, y_pred_lbl, target_names=class_names))\n",
        "\n",
        "cm = confusion_matrix(y_true_lbl, y_pred_lbl, normalize=None)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "plt.figure(figsize=(5,5))\n",
        "disp.plot(values_format='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81b7d054",
      "metadata": {
        "id": "81b7d054"
      },
      "source": [
        "## 8) Grad-CAM (Why the model thinks so)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "028a13ba",
      "metadata": {
        "id": "028a13ba"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-8)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "# Find last conv layer name in EfficientNetB0 backbone\n",
        "last_conv = None\n",
        "for layer in model.layers:\n",
        "    if hasattr(layer, \"name\") and \"efficientnetb0\" in layer.name:\n",
        "        # grab internal conv name via the base model\n",
        "        for l in layer.layers[::-1]:\n",
        "            if isinstance(l, tf.keras.layers.Conv2D):\n",
        "                last_conv = l.name\n",
        "                break\n",
        "        break\n",
        "\n",
        "print(\"Using last conv layer:\", last_conv)\n",
        "\n",
        "def show_gradcam(dataset, n=4):\n",
        "    it = dataset.unbatch().take(n)\n",
        "    for img, label in it:\n",
        "        img_np = tf.image.resize(img, IMG_SIZE).numpy()\n",
        "        img_batch = np.expand_dims(img_np, axis=0)\n",
        "        heatmap = make_gradcam_heatmap(img_batch, model, last_conv)\n",
        "        # overlay\n",
        "        heatmap_resized = tf.image.resize(heatmap[..., np.newaxis], IMG_SIZE).numpy().squeeze()\n",
        "        plt.figure(figsize=(8,3))\n",
        "        plt.subplot(1,3,1); plt.imshow(img_np.astype(\"uint8\")); plt.axis('off'); plt.title(\"Image\")\n",
        "        plt.subplot(1,3,2); plt.imshow(heatmap_resized, cmap='jet'); plt.axis('off'); plt.title(\"Grad-CAM\")\n",
        "        # overlay\n",
        "        overlay = img_np.astype(\"float32\")\n",
        "        overlay = (0.4 * overlay + 0.6 * (plt.cm.jet(heatmap_resized)[..., :3] * 255)).clip(0,255).astype(\"uint8\")\n",
        "        plt.subplot(1,3,3); plt.imshow(overlay); plt.axis('off'); plt.title(\"Overlay\")\n",
        "        plt.show()\n",
        "\n",
        "# Visualize a few\n",
        "show_gradcam(eval_ds, n=4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddc7362f",
      "metadata": {
        "id": "ddc7362f"
      },
      "source": [
        "## 9) Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a17d9ea",
      "metadata": {
        "id": "2a17d9ea"
      },
      "outputs": [],
      "source": [
        "\n",
        "SAVE_DIR = \"/content/drive/MyDrive/models/aivsreal_baseline\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "model.save(os.path.join(SAVE_DIR, \"effnetb0_aivsreal.h5\"))\n",
        "print(\"Saved to\", SAVE_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54bc9eab",
      "metadata": {
        "id": "54bc9eab"
      },
      "source": [
        "\n",
        "## ‚úÖ Next steps\n",
        "- Add **more data** and balance classes.\n",
        "- Try stronger backbones (e.g., `EfficientNetB3`, `ResNet50`, or `ViT` via `keras_cv`).\n",
        "- Add **augmentations** targeted at AI artifacts (e.g., JPEG re-compression, blur, noise) to improve robustness.\n",
        "- Run **k-fold cross-validation** for reliable metrics.\n",
        "- Log to **Weights & Biases** or **TensorBoard** for experiment tracking.\n",
        "- Consider **frequency-domain features** or **patch-level** training as enhancements.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}